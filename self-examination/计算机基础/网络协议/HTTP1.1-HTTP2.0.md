## HTTP/1.1、HTTP/2 带来的改变，再说说 HTTP/3

### HTTP/1,1

HTTP/1.1 是相对于 HTTP/1.0 的升级版本，引入了一些重要的改变，主要改变如下

- 新增方法: `OPTIONS`、`PATCH`、`DELETE`、`TRACE`、`CONNECT`

- 持久链接（Keep-alive）

  HTTP/1.1 默认使用持久链接，即在单个 TCP 连接上可以发送多个请求和相应（在 HTTP/1.0 中每个请求都需要开启一个 TCP 连接），减少了建立、关闭连接的开销

- 管线化（Pipelining）

  HTTP/1.1 引入了名为 “管线化” 的机制，旨在进一步提高 HTTP 的效率，通过一个 TCP 连接上连续发送多个请求而不等待相应的响应，来减少整体的延迟。管线化机制允许客户端在收到前一个请求的响应之前，发送后续的请求。

  然而，尽管可以连续发送，服务器必须按照请求收到的顺序发送响应。这意味着，如果第一个请求的处理时间较长，后续请求的响应即使已准备好也必须等待，直到第一个请求被处理完成。同时因为兼容性的问题和并未根本的解决队头阻塞，该机制并未被广泛使用

- 分块传输编码（Chunked Transfer Encoding）

  HTTP/1.1 支持将响应分块传输，而不是等待整个响应完全生成在发送，这对于大型响应和流式数据传输非常有用，可以提前开始传输数据，提高响应速度

- HOST 头部支持

  HTTP/1.1 引入了 HOST 头部，允许一台物理服务器上托管多个域名，提高虚拟主机的支持，通过 HOST 头部可以将请求分发到不同的虚拟主机，提高服务器资源的利用率

- 缓存控制

  HTTP/1.1 引入了更多的缓存控制机制，包括 `Etag`、`If-None-Match` 头部字段，提供更细密度的缓存控制和缓存验证机制
  `Etag`/`If-Node-Match`(HTTP/1.1) 与 `Last-Modified`/`If-Modified-Since`(HTTP/1.0) 的区别

  - `Etag/If-None-Match` 有更好的精确度，可以更深层的感知资源的变化，比如文件只是编辑过但是没有更改内容，这样也会造成缓存失效

  - `Last-Modified/If-Modified-Since` 有更好的性能，因为他只是记录一个时间点，而 `Etag` 需要根据文件具体内容生成哈希值

- 断点续传（Range Requests）

  HTTP/1.1 支持断点续传，允许客户端请求资源的指定范围，实现只下载部分内容，适用于大文件下载和断点续传的场景

- 身份验证（Authentication）

  HTTP/1.1 引入了更多的身份验证机制，如基本认证、摘要认证等，提供了更安全的身份验证方式

### HTTP/2

- 多路复用（Multiplexing）

  HTTP/2 中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双线数据流(stream)，每个数据流都以消息(message)的形式发送，消息是指少由一个 Header 帧组成的，多个帧之间可以乱序发送，根据帧中的流标识，在到达后进行组装，解决了 HTTP/1.1 对头阻塞的问题

- 二进制传输（Binary Protocol）

  HTTP/2 使用二进制格式进行数据传输，取代了 HTTP/1.1 的文本格式，这种二进制格式更加紧凑，解析效率更高，减少了数据传输的大小和网络延迟

- 头部压缩（Header Compression）

  HTTP/2 使用了 HPACK 压缩算法对头部信息进行压缩，减少了数据传输的大小。由于 HTTP/1.1 的头部信息经常重复传输，通过压缩可以大幅度减少数据量

- 服务器推送

  HTTP/2 允许服务器主动推送资源给客户端，无需客户端显式请求，当服务器发送响应时，可以在同一个 TCP 连接上推送其他相关资源，减少了客户端请求的延迟，提高了页面加载速度

- 流量控制

  HTTP/2 引入了流量控制机制，可以控制数据的传输速率，防止过载情况的发生

### HTTP/2 的缺点

- 连接延迟

  因为 HTTP/2 需要配合 HTTPS 使用，所以需要使用 TLS 协议进行安全传输，而 TLS 也需要一个握手过程，连带上 TCP 的握手，建立连接的过程可能需要 3~4 个 RTT（Round-Trip Time，往返时间）

- 对头阻塞

  HTTP/2 并没有从根本上解决对头阻塞的问题，这是因为其还是依赖于 TCP 连接，而由于 TCP 的 “可靠性” 的特性，有一个特别的 “丢包重传” 机制，即丢失的包必须要等待重新传输确认，所以当 HTTP/2 出现丢包时，整个 TCP 都要开始等待重新传输确认，所以当 HTTP/2 出现丢包时，整个 TCP 都要开始等待重传，如此一来就会堵塞该连接中的所有请求

- 多路复用导致服务器压力上升

  多路复用没有限制同时请求时，请求的平均数量于往常相同，但实际会有许多请求的短暂爆发，导致瞬间 QPS 暴增

- 丢包

  丢包是 HTTP/2 的命门，如果网络中的数据包没有成功到达目的地就会发生丢包，这通常是由于网络拥堵造成的。频繁的丢包会影响 HTTP/2 的页面传输，这是由于 TCP 会因为丢包缩减 TCP 窗口

### HTTP/3

HTTP/3 是最新的 HTTP 协议版本，它旨在进一步提升网络通信的速度和效率，同时解决 HTTP/2 在某些场景下遇到的问题。HTTP/3 的主要变化是引入了基于 QUIC（快速 UDP 互联网连接）的传输层协议，替代了之前的 TCP+TLS 组合

#### 背景

在 HTTP/2 中，尽管引入了多路复用、头部压缩等优化，但他仍然依赖于 TCP 协议。TCP 在建立连接时需要进行三次握手，且在遇到丢包时整个连接都会受到影响（缩减 TCP 窗口），这种现象被称为 “队头阻塞”。此外，TCP 的握手过程还需要额外的往返延迟来完成 TLS 加密协议的协商，增加了建立安全连接的成本

#### QUIC 协议

QUIC 是由 Google 开发的基于 UDP 的传输协议，它旨在解决 TCP 协议的一些核心问题，特别是队头阻塞的问题。QUIC 内置了加密功能，减少了连接和加密的往返次数。它支持无缝的连接迁移，即使网络环境变化（如用户的移动设备从 Wi-Fi 切换到移动网络）也能保持连接不断开

#### HTTP/3 的特点

- 减少连接延迟：QUIC 通过减少握手次数来加快连接的建立，理想情况下只需要一次往返就可以完成

- 解决对头阻塞：由于 QUIC 是基于 UDP 的，它允许独立的数据流互不干扰，一个数据包的丢失不会影响到其他数据包的传输

- 连接迁移：QUIC 支持连接 ID，即使底层的 IP 地址或端口变化，连接也可以继续维持，这对移动设备尤为有利

- 内置加密：QUIC 将 TLS 加密直接集成到了协议中，提高了数据传输的安全性

- 流量控制和拥塞控制：QUIC 实现了自己的流量控制和拥塞控制机制，以优化网络资源的使用和响应网络条件的变化
